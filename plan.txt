1. Web Scraping Logic:
Scrape the data portal website. 
Core of API, fetching real-time data from the source. 
Should be optimized to handle the structure of the data portal efficiently.

2. API Endpoint Creation:
Develop API endpoints that execute the scraping script. 
Endpoints will take user requests, scrape the necessary data, then return it in a structured format like JSON.

3.Handle Requests and Responses:
Ensure API can accept parameters from user requests (like specific tags or dataset names) 
and use them in the scraping logic to filter or search for specific datasets.

4. Error Handling and Validation: 
Implement robust error handling to manage issues like network errors, 
changes in the source websiteâ€™s structure, or empty responses.

5. Optimization:
Optimize your script for performance and reliability.
This might include improving the parsing logic, handling exceptions, and managing timeouts.

6. Integration and Testing:
Integrate this script with your web server framework (like Flask or Django for Python)
and thoroughly test the endpoints to ensure they return accurate and up-to-date data.

7. Create CRON jobs